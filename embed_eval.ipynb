{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from src.helper import load_checkpoint, init_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Specify the path to your trained checkpoint file\n",
    "# checkpoint_path = '/home/paritosh/workspace/ijepa_saved_models/jepa-latest.pth.tar'\n",
    "\n",
    "# # Initialize the device (e.g., 'cuda' or 'cpu')\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# # Load the checkpoint\n",
    "# checkpoint = torch.load(checkpoint_path, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract the model configuration from the checkpoint\n",
    "# config = checkpoint['config']\n",
    "\n",
    "# # # Initialize the device (e.g., 'cuda' or 'cpu')\n",
    "# # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# # Extract the relevant parameters from the configuration\n",
    "# patch_size = config['mask']['patch_size']\n",
    "# model_name = config['meta']['model_name']\n",
    "# crop_size = config['data']['crop_size']\n",
    "# pred_depth = config['meta']['pred_depth']\n",
    "# pred_emb_dim = config['meta']['pred_emb_dim']\n",
    "\n",
    "# # Initialize the model components\n",
    "# encoder, predictor = init_model(\n",
    "#     device,\n",
    "#     patch_size=patch_size,\n",
    "#     model_name=model_name,\n",
    "#     crop_size=crop_size,\n",
    "#     pred_depth=pred_depth,\n",
    "#     pred_emb_dim=pred_emb_dim\n",
    "# )\n",
    "\n",
    "# target_encoder = None\n",
    "# optimizer = None\n",
    "# scaler = None\n",
    "\n",
    "# # Load the checkpoint\n",
    "# encoder, predictor, target_encoder, optimizer, scaler, epoch = load_checkpoint(\n",
    "#     device,\n",
    "#     checkpoint_path,\n",
    "#     encoder,\n",
    "#     predictor,\n",
    "#     target_encoder,\n",
    "#     optimizer,\n",
    "#     scaler\n",
    "# )\n",
    "\n",
    "# # Print the model structure\n",
    "# print(\"Encoder:\")\n",
    "# print(encoder)\n",
    "# print(\"\\nPredictor:\")\n",
    "# print(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:VisionTransformer(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 384, kernel_size=(4, 4), stride=(4, 4))\n",
      "  )\n",
      "  (blocks): ModuleList(\n",
      "    (0-11): 12 x Block(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): MLP(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      ")\n",
      "INFO:root:Encountered exception when loading checkpoint Error(s) in loading state_dict for VisionTransformer:\n",
      "\tMissing key(s) in state_dict: \"pos_embed\", \"patch_embed.proj.weight\", \"patch_embed.proj.bias\", \"blocks.0.norm1.weight\", \"blocks.0.norm1.bias\", \"blocks.0.attn.qkv.weight\", \"blocks.0.attn.qkv.bias\", \"blocks.0.attn.proj.weight\", \"blocks.0.attn.proj.bias\", \"blocks.0.norm2.weight\", \"blocks.0.norm2.bias\", \"blocks.0.mlp.fc1.weight\", \"blocks.0.mlp.fc1.bias\", \"blocks.0.mlp.fc2.weight\", \"blocks.0.mlp.fc2.bias\", \"blocks.1.norm1.weight\", \"blocks.1.norm1.bias\", \"blocks.1.attn.qkv.weight\", \"blocks.1.attn.qkv.bias\", \"blocks.1.attn.proj.weight\", \"blocks.1.attn.proj.bias\", \"blocks.1.norm2.weight\", \"blocks.1.norm2.bias\", \"blocks.1.mlp.fc1.weight\", \"blocks.1.mlp.fc1.bias\", \"blocks.1.mlp.fc2.weight\", \"blocks.1.mlp.fc2.bias\", \"blocks.2.norm1.weight\", \"blocks.2.norm1.bias\", \"blocks.2.attn.qkv.weight\", \"blocks.2.attn.qkv.bias\", \"blocks.2.attn.proj.weight\", \"blocks.2.attn.proj.bias\", \"blocks.2.norm2.weight\", \"blocks.2.norm2.bias\", \"blocks.2.mlp.fc1.weight\", \"blocks.2.mlp.fc1.bias\", \"blocks.2.mlp.fc2.weight\", \"blocks.2.mlp.fc2.bias\", \"blocks.3.norm1.weight\", \"blocks.3.norm1.bias\", \"blocks.3.attn.qkv.weight\", \"blocks.3.attn.qkv.bias\", \"blocks.3.attn.proj.weight\", \"blocks.3.attn.proj.bias\", \"blocks.3.norm2.weight\", \"blocks.3.norm2.bias\", \"blocks.3.mlp.fc1.weight\", \"blocks.3.mlp.fc1.bias\", \"blocks.3.mlp.fc2.weight\", \"blocks.3.mlp.fc2.bias\", \"blocks.4.norm1.weight\", \"blocks.4.norm1.bias\", \"blocks.4.attn.qkv.weight\", \"blocks.4.attn.qkv.bias\", \"blocks.4.attn.proj.weight\", \"blocks.4.attn.proj.bias\", \"blocks.4.norm2.weight\", \"blocks.4.norm2.bias\", \"blocks.4.mlp.fc1.weight\", \"blocks.4.mlp.fc1.bias\", \"blocks.4.mlp.fc2.weight\", \"blocks.4.mlp.fc2.bias\", \"blocks.5.norm1.weight\", \"blocks.5.norm1.bias\", \"blocks.5.attn.qkv.weight\", \"blocks.5.attn.qkv.bias\", \"blocks.5.attn.proj.weight\", \"blocks.5.attn.proj.bias\", \"blocks.5.norm2.weight\", \"blocks.5.norm2.bias\", \"blocks.5.mlp.fc1.weight\", \"blocks.5.mlp.fc1.bias\", \"blocks.5.mlp.fc2.weight\", \"blocks.5.mlp.fc2.bias\", \"blocks.6.norm1.weight\", \"blocks.6.norm1.bias\", \"blocks.6.attn.qkv.weight\", \"blocks.6.attn.qkv.bias\", \"blocks.6.attn.proj.weight\", \"blocks.6.attn.proj.bias\", \"blocks.6.norm2.weight\", \"blocks.6.norm2.bias\", \"blocks.6.mlp.fc1.weight\", \"blocks.6.mlp.fc1.bias\", \"blocks.6.mlp.fc2.weight\", \"blocks.6.mlp.fc2.bias\", \"blocks.7.norm1.weight\", \"blocks.7.norm1.bias\", \"blocks.7.attn.qkv.weight\", \"blocks.7.attn.qkv.bias\", \"blocks.7.attn.proj.weight\", \"blocks.7.attn.proj.bias\", \"blocks.7.norm2.weight\", \"blocks.7.norm2.bias\", \"blocks.7.mlp.fc1.weight\", \"blocks.7.mlp.fc1.bias\", \"blocks.7.mlp.fc2.weight\", \"blocks.7.mlp.fc2.bias\", \"blocks.8.norm1.weight\", \"blocks.8.norm1.bias\", \"blocks.8.attn.qkv.weight\", \"blocks.8.attn.qkv.bias\", \"blocks.8.attn.proj.weight\", \"blocks.8.attn.proj.bias\", \"blocks.8.norm2.weight\", \"blocks.8.norm2.bias\", \"blocks.8.mlp.fc1.weight\", \"blocks.8.mlp.fc1.bias\", \"blocks.8.mlp.fc2.weight\", \"blocks.8.mlp.fc2.bias\", \"blocks.9.norm1.weight\", \"blocks.9.norm1.bias\", \"blocks.9.attn.qkv.weight\", \"blocks.9.attn.qkv.bias\", \"blocks.9.attn.proj.weight\", \"blocks.9.attn.proj.bias\", \"blocks.9.norm2.weight\", \"blocks.9.norm2.bias\", \"blocks.9.mlp.fc1.weight\", \"blocks.9.mlp.fc1.bias\", \"blocks.9.mlp.fc2.weight\", \"blocks.9.mlp.fc2.bias\", \"blocks.10.norm1.weight\", \"blocks.10.norm1.bias\", \"blocks.10.attn.qkv.weight\", \"blocks.10.attn.qkv.bias\", \"blocks.10.attn.proj.weight\", \"blocks.10.attn.proj.bias\", \"blocks.10.norm2.weight\", \"blocks.10.norm2.bias\", \"blocks.10.mlp.fc1.weight\", \"blocks.10.mlp.fc1.bias\", \"blocks.10.mlp.fc2.weight\", \"blocks.10.mlp.fc2.bias\", \"blocks.11.norm1.weight\", \"blocks.11.norm1.bias\", \"blocks.11.attn.qkv.weight\", \"blocks.11.attn.qkv.bias\", \"blocks.11.attn.proj.weight\", \"blocks.11.attn.proj.bias\", \"blocks.11.norm2.weight\", \"blocks.11.norm2.bias\", \"blocks.11.mlp.fc1.weight\", \"blocks.11.mlp.fc1.bias\", \"blocks.11.mlp.fc2.weight\", \"blocks.11.mlp.fc2.bias\", \"norm.weight\", \"norm.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"module.pos_embed\", \"module.patch_embed.proj.weight\", \"module.patch_embed.proj.bias\", \"module.blocks.0.norm1.weight\", \"module.blocks.0.norm1.bias\", \"module.blocks.0.attn.qkv.weight\", \"module.blocks.0.attn.qkv.bias\", \"module.blocks.0.attn.proj.weight\", \"module.blocks.0.attn.proj.bias\", \"module.blocks.0.norm2.weight\", \"module.blocks.0.norm2.bias\", \"module.blocks.0.mlp.fc1.weight\", \"module.blocks.0.mlp.fc1.bias\", \"module.blocks.0.mlp.fc2.weight\", \"module.blocks.0.mlp.fc2.bias\", \"module.blocks.1.norm1.weight\", \"module.blocks.1.norm1.bias\", \"module.blocks.1.attn.qkv.weight\", \"module.blocks.1.attn.qkv.bias\", \"module.blocks.1.attn.proj.weight\", \"module.blocks.1.attn.proj.bias\", \"module.blocks.1.norm2.weight\", \"module.blocks.1.norm2.bias\", \"module.blocks.1.mlp.fc1.weight\", \"module.blocks.1.mlp.fc1.bias\", \"module.blocks.1.mlp.fc2.weight\", \"module.blocks.1.mlp.fc2.bias\", \"module.blocks.2.norm1.weight\", \"module.blocks.2.norm1.bias\", \"module.blocks.2.attn.qkv.weight\", \"module.blocks.2.attn.qkv.bias\", \"module.blocks.2.attn.proj.weight\", \"module.blocks.2.attn.proj.bias\", \"module.blocks.2.norm2.weight\", \"module.blocks.2.norm2.bias\", \"module.blocks.2.mlp.fc1.weight\", \"module.blocks.2.mlp.fc1.bias\", \"module.blocks.2.mlp.fc2.weight\", \"module.blocks.2.mlp.fc2.bias\", \"module.blocks.3.norm1.weight\", \"module.blocks.3.norm1.bias\", \"module.blocks.3.attn.qkv.weight\", \"module.blocks.3.attn.qkv.bias\", \"module.blocks.3.attn.proj.weight\", \"module.blocks.3.attn.proj.bias\", \"module.blocks.3.norm2.weight\", \"module.blocks.3.norm2.bias\", \"module.blocks.3.mlp.fc1.weight\", \"module.blocks.3.mlp.fc1.bias\", \"module.blocks.3.mlp.fc2.weight\", \"module.blocks.3.mlp.fc2.bias\", \"module.blocks.4.norm1.weight\", \"module.blocks.4.norm1.bias\", \"module.blocks.4.attn.qkv.weight\", \"module.blocks.4.attn.qkv.bias\", \"module.blocks.4.attn.proj.weight\", \"module.blocks.4.attn.proj.bias\", \"module.blocks.4.norm2.weight\", \"module.blocks.4.norm2.bias\", \"module.blocks.4.mlp.fc1.weight\", \"module.blocks.4.mlp.fc1.bias\", \"module.blocks.4.mlp.fc2.weight\", \"module.blocks.4.mlp.fc2.bias\", \"module.blocks.5.norm1.weight\", \"module.blocks.5.norm1.bias\", \"module.blocks.5.attn.qkv.weight\", \"module.blocks.5.attn.qkv.bias\", \"module.blocks.5.attn.proj.weight\", \"module.blocks.5.attn.proj.bias\", \"module.blocks.5.norm2.weight\", \"module.blocks.5.norm2.bias\", \"module.blocks.5.mlp.fc1.weight\", \"module.blocks.5.mlp.fc1.bias\", \"module.blocks.5.mlp.fc2.weight\", \"module.blocks.5.mlp.fc2.bias\", \"module.blocks.6.norm1.weight\", \"module.blocks.6.norm1.bias\", \"module.blocks.6.attn.qkv.weight\", \"module.blocks.6.attn.qkv.bias\", \"module.blocks.6.attn.proj.weight\", \"module.blocks.6.attn.proj.bias\", \"module.blocks.6.norm2.weight\", \"module.blocks.6.norm2.bias\", \"module.blocks.6.mlp.fc1.weight\", \"module.blocks.6.mlp.fc1.bias\", \"module.blocks.6.mlp.fc2.weight\", \"module.blocks.6.mlp.fc2.bias\", \"module.blocks.7.norm1.weight\", \"module.blocks.7.norm1.bias\", \"module.blocks.7.attn.qkv.weight\", \"module.blocks.7.attn.qkv.bias\", \"module.blocks.7.attn.proj.weight\", \"module.blocks.7.attn.proj.bias\", \"module.blocks.7.norm2.weight\", \"module.blocks.7.norm2.bias\", \"module.blocks.7.mlp.fc1.weight\", \"module.blocks.7.mlp.fc1.bias\", \"module.blocks.7.mlp.fc2.weight\", \"module.blocks.7.mlp.fc2.bias\", \"module.blocks.8.norm1.weight\", \"module.blocks.8.norm1.bias\", \"module.blocks.8.attn.qkv.weight\", \"module.blocks.8.attn.qkv.bias\", \"module.blocks.8.attn.proj.weight\", \"module.blocks.8.attn.proj.bias\", \"module.blocks.8.norm2.weight\", \"module.blocks.8.norm2.bias\", \"module.blocks.8.mlp.fc1.weight\", \"module.blocks.8.mlp.fc1.bias\", \"module.blocks.8.mlp.fc2.weight\", \"module.blocks.8.mlp.fc2.bias\", \"module.blocks.9.norm1.weight\", \"module.blocks.9.norm1.bias\", \"module.blocks.9.attn.qkv.weight\", \"module.blocks.9.attn.qkv.bias\", \"module.blocks.9.attn.proj.weight\", \"module.blocks.9.attn.proj.bias\", \"module.blocks.9.norm2.weight\", \"module.blocks.9.norm2.bias\", \"module.blocks.9.mlp.fc1.weight\", \"module.blocks.9.mlp.fc1.bias\", \"module.blocks.9.mlp.fc2.weight\", \"module.blocks.9.mlp.fc2.bias\", \"module.blocks.10.norm1.weight\", \"module.blocks.10.norm1.bias\", \"module.blocks.10.attn.qkv.weight\", \"module.blocks.10.attn.qkv.bias\", \"module.blocks.10.attn.proj.weight\", \"module.blocks.10.attn.proj.bias\", \"module.blocks.10.norm2.weight\", \"module.blocks.10.norm2.bias\", \"module.blocks.10.mlp.fc1.weight\", \"module.blocks.10.mlp.fc1.bias\", \"module.blocks.10.mlp.fc2.weight\", \"module.blocks.10.mlp.fc2.bias\", \"module.blocks.11.norm1.weight\", \"module.blocks.11.norm1.bias\", \"module.blocks.11.attn.qkv.weight\", \"module.blocks.11.attn.qkv.bias\", \"module.blocks.11.attn.proj.weight\", \"module.blocks.11.attn.proj.bias\", \"module.blocks.11.norm2.weight\", \"module.blocks.11.norm2.bias\", \"module.blocks.11.mlp.fc1.weight\", \"module.blocks.11.mlp.fc1.bias\", \"module.blocks.11.mlp.fc2.weight\", \"module.blocks.11.mlp.fc2.bias\", \"module.norm.weight\", \"module.norm.bias\". \n",
      "Encoder:\n",
      "VisionTransformer(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 384, kernel_size=(4, 4), stride=(4, 4))\n",
      "  )\n",
      "  (blocks): ModuleList(\n",
      "    (0-11): 12 x Block(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): MLP(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      ")\n",
      "\n",
      "Predictor:\n",
      "VisionTransformerPredictor(\n",
      "  (predictor_embed): Linear(in_features=384, out_features=192, bias=True)\n",
      "  (predictor_blocks): ModuleList(\n",
      "    (0-7): 8 x Block(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): MLP(\n",
      "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (predictor_norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "  (predictor_proj): Linear(in_features=192, out_features=384, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import yaml\n",
    "from src.helper import load_checkpoint, init_model\n",
    "\n",
    "# Specify the path to your trained checkpoint file\n",
    "checkpoint_path = '/home/paritosh/workspace/ijepa_saved_models/jepa-latest.pth.tar'\n",
    "\n",
    "# Specify the path to your YAML configuration file\n",
    "config_path = 'configs/custom1.yaml'\n",
    "\n",
    "# Load the YAML configuration file\n",
    "with open(config_path, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Initialize the device (e.g., 'cuda' or 'cpu')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Extract the relevant parameters from the configuration\n",
    "patch_size = config['mask']['patch_size']\n",
    "model_name = config['meta']['model_name']\n",
    "crop_size = config['data']['crop_size']\n",
    "pred_depth = config['meta']['pred_depth']\n",
    "pred_emb_dim = config['meta']['pred_emb_dim']\n",
    "\n",
    "# Initialize the model components\n",
    "encoder, predictor = init_model(\n",
    "    device,\n",
    "    patch_size=patch_size,\n",
    "    model_name=model_name,\n",
    "    crop_size=crop_size,\n",
    "    pred_depth=pred_depth,\n",
    "    pred_emb_dim=pred_emb_dim\n",
    ")\n",
    "\n",
    "target_encoder = None\n",
    "optimizer = None\n",
    "scaler = None\n",
    "\n",
    "# Load the checkpoint\n",
    "encoder, predictor, target_encoder, optimizer, scaler, epoch = load_checkpoint(\n",
    "    device,\n",
    "    checkpoint_path,\n",
    "    encoder,\n",
    "    predictor,\n",
    "    target_encoder,\n",
    "    optimizer,\n",
    "    scaler\n",
    ")\n",
    "\n",
    "# Print the model structure\n",
    "print(\"Encoder:\")\n",
    "print(encoder)\n",
    "print(\"\\nPredictor:\")\n",
    "print(predictor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jepa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
